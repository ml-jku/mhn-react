{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/system/user/publicwork/seidl/projects/mhn-react\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast and efficient retrieval using a trained model\n",
    "After training the model can be used as embedding-model and templates can be efficiently retrieved, instead of allways holding all templates in gpu-memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeded with 0\n",
      "loading X, y from csv\n",
      "test 5007 samples\n",
      "valid 5001 samples\n",
      "train 40008 samples\n",
      "11800 templates\n",
      "[759, 355, 241, 210, 138, 132, 90, 99, 69, 49, 44, 2821, 1852]\n",
      "{'fingerprint_type': 'morgan', 'template_fp_type': 'rdk', 'num_templates': 11800, 'fp_size': 4096, 'fp_radius': 2, 'device': 'cuda:0', 'batch_size': 128, 'pooling_operation_state_embedding': 'mean', 'pooling_operation_head': 'max', 'dropout': 0.2, 'lr': 0.0005, 'optimizer': 'Adam', 'activation_function': 'ReLU', 'verbose': False, 'hopf_input_size': 4096, 'hopf_output_size': None, 'hopf_num_heads': 1, 'hopf_asso_dim': 512, 'hopf_association_activation': 'None', 'hopf_beta': 0.05, 'norm_input': True, 'norm_asso': True, 'hopf_n_layers': 1, 'mol_encoder_layers': 1, 'temp_encoder_layers': 1, 'encoder_af': 'ReLU', 'hopf_pooling_operation_head': 'mean'}\n",
      "loading tfp from file ./data/cache/templ_emb_4096_rdk2_11800_319308756406610263009709791057247232169953402565012761665882794469049907419597432806619930615825219861593907665538161448220007278140048617814857686486870.npy\n",
      "313it [00:15, 20.61it/s]\n",
      " 0 -- train_loss: 4.206, loss_valid: 3.770, val_t1acc: 0.200, val_t100acc: 0.880\n",
      "313it [00:14, 21.71it/s]\n",
      " 1 -- train_loss: 2.972, loss_valid: 3.409, val_t1acc: 0.226, val_t100acc: 0.910\n",
      "313it [00:14, 21.74it/s]\n",
      " 2 -- train_loss: 2.407, loss_valid: 3.275, val_t1acc: 0.231, val_t100acc: 0.913\n",
      "313it [00:14, 22.27it/s]\n",
      " 3 -- train_loss: 2.057, loss_valid: 3.254, val_t1acc: 0.236, val_t100acc: 0.913\n",
      "313it [00:14, 21.85it/s]\n",
      " 4 -- train_loss: 1.823, loss_valid: 3.252, val_t1acc: 0.239, val_t100acc: 0.913\n",
      "313it [00:14, 21.84it/s]\n",
      " 5 -- train_loss: 1.687, loss_valid: 3.251, val_t1acc: 0.241, val_t100acc: 0.912\n",
      "313it [00:14, 21.55it/s]\n",
      " 6 -- train_loss: 1.552, loss_valid: 3.241, val_t1acc: 0.241, val_t100acc: 0.912\n",
      "313it [00:14, 21.64it/s]\n",
      " 7 -- train_loss: 1.475, loss_valid: 3.267, val_t1acc: 0.242, val_t100acc: 0.910\n",
      "313it [00:14, 21.63it/s]\n",
      " 8 -- train_loss: 1.448, loss_valid: 3.283, val_t1acc: 0.238, val_t100acc: 0.904\n",
      "313it [00:14, 21.70it/s]\n",
      " 9 -- train_loss: 1.367, loss_valid: 3.285, val_t1acc: 0.239, val_t100acc: 0.906\n",
      "model saved to data/model/USPTO_50k_mhn_valloss3.285_rerun_1693819455.pt\n",
      "3.241067260503769\n"
     ]
    }
   ],
   "source": [
    "# train a model if you haven't already (these parameters will produce and ok-ish model fast ;) \n",
    "!python -m mhnreact.train --model_type=mhn --device=best --fp_size=4096  --fp_type morgan --template_fp_type rdk --concat_rand_template_thresh -1 \\\n",
    "--exp_name rerun --dataset_type 50k --csv_path ./data/USPTO_50k_MHN_prepro.csv.gz --split_col split --ssretroeval False --seed 0 \\\n",
    "--hopf_association_activation None --fp_radius 2 --save_model True\n",
    "# norm_asso should be True (but is so by default)\n",
    "# concat_rand_template_thresh -1 means we don't add noise to template classification to make them better distinguishable; \n",
    "# reduces top-1 performance but should be better for retrieval from a new set of templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fingerprint_type': 'morgan', 'template_fp_type': 'rdk', 'num_templates': 11800, 'fp_size': 4096, 'fp_radius': 2, 'device': 'cpu', 'batch_size': 128, 'pooling_operation_state_embedding': 'mean', 'pooling_operation_head': 'max', 'dropout': 0.2, 'lr': 0.0005, 'optimizer': 'Adam', 'activation_function': 'ReLU', 'verbose': False, 'hopf_input_size': 4096, 'hopf_output_size': None, 'hopf_num_heads': 1, 'hopf_asso_dim': 512, 'hopf_association_activation': 'None', 'hopf_beta': 0.05, 'norm_input': True, 'norm_asso': True, 'hopf_n_layers': 0, 'mol_encoder_layers': 1, 'temp_encoder_layers': 1, 'encoder_af': 'ReLU', 'hopf_pooling_operation_head': 'mean'}\n"
     ]
    }
   ],
   "source": [
    "# now we can load in the model (this will take the first of your models in the model directory);\n",
    "# you can also specify your own model dir by passing the model_path argument\n",
    "from mhnreact.inspect import *\n",
    "clf = load_clf(model_fn=list_models()[0], model_type='mhn', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get templates from USPTO-full (230k templates)\n",
    "# for USPTO_full_MHN_prepro_woiv run the notebook 03_prepro_uspto_full\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"/system/user/seidl/seidl/projects/projects/mhn-react/data/USPTO_full_MHN_prepro_woiv.csv.gz\")\n",
    "#df = pd.read_csv(\"./data/USPTO_50k_MHN_prepro.csv.gz\") # USPTO-sm\n",
    "\n",
    "tmp = df[['reaction_smarts','label']].drop_duplicates(subset=['reaction_smarts','label']).sort_values('label')\n",
    "# drop the ones from the test set\n",
    "\n",
    "tmp.index= tmp.label\n",
    "template_list = tmp['reaction_smarts'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278546"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "templates = list(template_list.values())\n",
    "len(templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode templates\n",
    "xd = clf.encode_templates(templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278546, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install autofaiss\n",
    "#!pip install autofaiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use faiss to build index\n",
    "import faiss\n",
    "index = faiss.IndexFlatIP(xd.shape[1])\n",
    "index.add(xd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "faiss.write_index(index, \"./data/templates.index\")\n",
    "# load from disk\n",
    "# index = faiss.read_index(\"./data/templates.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use autofaiss to build index\n",
    "# cosine similarity to find similar templates\n",
    "# uses less memory and picks an appropriate index type automatically\n",
    "# more prone to false positives than exact search --> experiment: USPTO-sm 70% (vs 90% exact template match accuracy)\n",
    "#from autofaiss import build_index\n",
    "#index, index_infos = build_index(xd, save_on_disk=True, \n",
    "#                            index_path=\"./data/templates.index\", metric_type='ip', min_nearest_neighbors_to_retrieve=20, \n",
    "#                            use_gpu=False, make_direct_map=False) # ip = inner product (cosine sim if vectors are normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556M\t./data/templates.index\n"
     ]
    }
   ],
   "source": [
    "# check memory usage \n",
    "!du -sh ./data/templates.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.140924536"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check memory of numpy array in GB\n",
    "import sys\n",
    "sys.getsizeof(xd)/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's evaluate the test set this way (we trained on USPTO-sm but test on USPTO-full zero-shot)\n",
    "n_samples = 1000\n",
    "xq = clf.encode_smiles(df[df.split==\"test\"].prod_smiles[:n_samples].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[df.split==\"test\"].label.values.tolist() # the template that should have been retrieved\n",
    "y = np.array(y)[:n_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 35s, sys: 578 ms, total: 7min 35s\n",
      "Wall time: 7.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# retrieve top k templates using the MHN-encoded molecule\n",
    "k=100\n",
    "_, I = index.search(xq, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-   1 accuracy:   4.10%\n",
      "top-   2 accuracy:   7.70%\n",
      "top-   3 accuracy:  10.50%\n",
      "top-   5 accuracy:  13.40%\n",
      "top-  10 accuracy:  19.20%\n",
      "top-  20 accuracy:  26.00%\n",
      "top-  50 accuracy:  33.60%\n",
      "top- 100 accuracy:  38.90%\n"
     ]
    }
   ],
   "source": [
    "# top-k accuracy\n",
    "for k in [1,2,3,5,10,20,50,100]:\n",
    "    print(f\"top-{k: 4d} accuracy: {(y[:,None]==I[:,:k]).any(axis=1).mean()*100: 6.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.2 s, sys: 4.45 s, total: 44.6 s\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# retrieve using a dot-droduct via numpy\n",
    "# besides being slower, it also uses more memory\n",
    "import numpy as np\n",
    "I_np = np.argsort(np.dot(xq[:], xd.T), axis=1)[:,-k:][:,::-1]\n",
    "# to do this more efficently one can used argpartion beforehand ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-   1 accuracy:   4.10%\n",
      "top-   2 accuracy:   7.70%\n",
      "top-   3 accuracy:  10.50%\n",
      "top-   5 accuracy:  13.40%\n",
      "top-  10 accuracy:  19.20%\n",
      "top-  20 accuracy:  26.00%\n",
      "top-  50 accuracy:  33.60%\n",
      "top- 100 accuracy:  38.90%\n"
     ]
    }
   ],
   "source": [
    "# top-k accuracy\n",
    "for k in [1,2,3,5,10,20,50,100]:\n",
    "    print(f\"top-{k: 4d} accuracy: {(y[:n_samples,None]==I[:,:k]).any(axis=1).mean()*100: 6.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.94507689235071"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(y==I[:,0]).mean()*100 # top 1 accuracy\n",
    "# top1 acc: 25% for USPTO-sm\n",
    "# top100 acc: 90% for USPTO-sm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
